{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!pip install fastai\n",
        "!pip install sklearn\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "Mh89ewZ984Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df['input'] = 'TEXT1: ' + df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor\n",
        "df"
      ],
      "metadata": {
        "id": "MGHwpAgv8_qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Transformers uses a Dataset object for storing a dataset\n",
        "ds = Dataset.from_pandas(df)\n",
        "ds\n",
        "\n",
        "model_nm = 'microsoft/deberta-v3-small'\n"
      ],
      "metadata": {
        "id": "n6Pb3cP29T0g"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
        "\n",
        "tokz = AutoTokenizer.from_pretrained(model_nm)\n",
        "tokz.tokenize(\"G'day folks, I'm Jeremy from fast.ai!\")\n"
      ],
      "metadata": {
        "id": "wjqtR7Vx9n3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tok_func(x):\n",
        "  return tokz(x[\"input\"])\n",
        "\n",
        "# to run it in parallel and fast\n",
        "tok_ds = ds.map(tok_func, batched=True)\n",
        "\n",
        "row = tok_ds[0]\n",
        "row['input'], row['input_ids']\n",
        "\n",
        "# to prepare the labels for the transformers, we rename the column as labels\n",
        "tok_ds = tok_ds.rename_columns({'score':'labels'})\n",
        "\n"
      ],
      "metadata": {
        "id": "WLG8TwNk9sl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df = pd.read_csv('test.csv')\n",
        "eval_df.describe()\n"
      ],
      "metadata": {
        "id": "9IJSMmyX-NJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model.selection import train_test_split\n",
        "#validation set\n",
        "dds = tok_ds.train_test_split(0.25, seed=42)\n",
        "print(dds)\n",
        "\n",
        "#test set\n",
        "eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\n",
        "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jcm69xRa-jb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_d(eval_pred):\n",
        "  return {'pearson': corr(*eval_pred)}\n",
        ""
      ],
      "metadata": {
        "id": "CavOdo7O-83L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainnig the model\n",
        "def corr_d(eval_pred):\n",
        "  return {'pearson': corr(*eval_pred)}\n",
        "\n",
        "bs = 128\n",
        "epochs = 4\n",
        "lr = 8e-5\n",
        "\n",
        "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
        "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
        "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
        "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
        "                  tokenizer=tokz, compute_metrics=corr_d)\n",
        "\n",
        "\n",
        "trainer.train();\n"
      ],
      "metadata": {
        "id": "Kz9NPWEM_GWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
        "print(preds)\n",
        "\n",
        "preds = np.clip(preds, 0, 1)\n",
        "print(preds)\n"
      ],
      "metadata": {
        "id": "3HJFijSl_Ucb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visulizing the predictions\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "# Scatter plot\n",
        "plt.scatter(data[:, 0], data[:, 1], c=data[:, 2], cmap='hot')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6DwR92D5_kgt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}